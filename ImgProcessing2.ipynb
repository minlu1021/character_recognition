{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "from PIL import Image \n",
    "import sys \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImgProcessing\n",
    "\n",
    "\n",
    "### HandWritten Image Processing\n",
    "\n",
    "* Load the images. \n",
    "\n",
    "The images are in .png format, so they can simply been loaded by PIL Library in Python. Each image is represented by a m*n matrix, m stands for the height of the image, n stands for the width and each cell of the matrices is a pixel, in (r, g, b) format.\n",
    "\n",
    "* Cut the margins.\n",
    "\n",
    "The images are not exactly a bounding box to the characters, the margins change the relative position of characters in each imag and influence the accuracy of classification. So we find the contour of the characters and cut the white margins. This step improve the accuracy significantly, as for KNN, the accuracy is raised from 55% to 93%, as for Neural Network, ....\n",
    "\n",
    "* Convert to binary images.\n",
    "\n",
    "Set a threshold for black pixel. If the value of a pixel reach the threshold, we turn this pixel into black, otherwise, we set this pixel to white. After this process, we get a binary image, only black and white.\n",
    "\n",
    "* Resize the images. \n",
    "\n",
    "Each image is 1200 pixels in width and 900 pixels in height. There is no need to analyze based on such a high resolution. According to the project experience of MNIST data, 8\\*8 matrix is enough for each image. So we resize the part of character to 120 \\*120. Though the height-width ratio has been changed, it doesn't matter. \n",
    "Since we have 26 characters and for each character there are 55 images, now our data matrix is 55\\*26\\*120\\*120.\n",
    "\n",
    "\n",
    "### Colorful Image Processing\n",
    "\n",
    "* Load the images. \n",
    "\n",
    "The same as the first step in handwrriten image processing part. Each character has different number of colorful samples, so finally we got 2832 samples.\n",
    "\n",
    "* Do grey processing.\n",
    "\n",
    "There are several methods to grey the image, such as take the average of r, g and b or take the maximum or minimum value among r, g, b. Here we replace the value of the pixel by the average of red, green and blue. Now the pixel has been converted from (r,g,b) format to a float.\n",
    "\n",
    "* Convert to binary images\n",
    "\n",
    "The same as the second step in handwritten image processing part.\n",
    "\n",
    "* Resize the images.\n",
    "\n",
    "Though the images have no extra margins when compared to handwritten images, the colorful images are not in same size. The testdata shuold have same dimensions, so we resize the images to 50 \\* 50. (Why not 120 \\* 120, the same as handwritten part? Because the original images are very small, some alreay smaller than 120 \\* 120, I don't want to stretch them.) Now the size of testdata is 2832 \\* 50 \\* 50.\n",
    "\n",
    "* Inverting, swelling and erosion.\n",
    "\n",
    "(I am sorry for the wrong spelling of erosion in the code...)\n",
    "We consider black part as character and white part as margin by default. But in some images, white part is the character and black part is the character, exactly the opposite situation. So I tried to distinguish whether a image need invert or not based on the mean value of the pixels on the (i don't know how to say, just the first row, the last row, the first column, the last column) which usually be considered as margin. If the mean value is more like black instead of white, we invert the color of the whole picture.\n",
    "Besides, after the greying, no doubt that there will be a lot of noises on the images. I do swelling and erosion.\n",
    "Swelling means if a pixel is black, then we turn all its neighbors into black. Erosion is the opposite process, it just turn the white pixels neighbor into white.\n",
    "The sequence of applying swelling and erosion matters. Swelling first can help you get rid of the noise points, but erosion first can prevent you from eliminating some thin part of the character.\n",
    "\n",
    "\n",
    "the coverage of black pixels which should be less than white pixels in common sense.\n",
    "\n",
    "\n",
    "\n",
    "After this step, accuracy can been raised from 50% to 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newwidth = 50\n",
    "newheight = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(tmp):\n",
    "    tmp = np.array(tmp).reshape(newheight, newwidth)\n",
    "    \n",
    "    # find threshold\n",
    "    maxlist = []\n",
    "    minlist = []\n",
    "    for h in range(newheight):\n",
    "        maxlist.append(max(tmp[h]))\n",
    "        minlist.append(min(tmp[h]))\n",
    "        \n",
    "    lowthreshold = min(minlist)\n",
    "    highthreshold = max(maxlist)\n",
    "               \n",
    "    # decide whether reverse the colors or not\n",
    "    margin = []\n",
    "    margin.append(tmp[0])\n",
    "    margin.append(tmp[newheight - 1])\n",
    "    margin.append(tmp[:, 0])\n",
    "    margin.append(tmp[:, newwidth - 1])\n",
    "    margin = np.array(margin).flatten()\n",
    "    \n",
    "    reverse = False\n",
    "    if margin.mean() - lowthreshold > highthreshold - margin.mean():\n",
    "        reverse = True\n",
    "    \n",
    "    # make colors more obvious\n",
    "    \n",
    "    for h in range(newheight):\n",
    "        for w in range(newwidth):\n",
    "            if reverse:\n",
    "                tmp[h][w] = 1 - tmp[h][w]\n",
    "                highthresholdtmp = 1 - lowthreshold\n",
    "                lowthreshold = 1 - highthreshold\n",
    "                highthreshold = highthresholdtmp\n",
    "            if tmp[h][w] <= lowthreshold + (highthreshold - lowthreshold) / float(10) * 4.5:\n",
    "                tmp[h][w] = 0\n",
    "            if tmp[h][w] >= highthreshold - (highthreshold - lowthreshold) * 0.55:\n",
    "                tmp[h][w] = 1\n",
    "\n",
    "    return tmp\n",
    "\n",
    "def errosion(tmp):\n",
    "    copy = tmp.copy()\n",
    "    for i in range(len(tmp)):\n",
    "        for j in range(len(tmp[0])):\n",
    "            if copy[i][j] == 0:\n",
    "                if i > 0 and j > 0 and i < len(tmp) - 1 and j < len(tmp[0]) - 1:\n",
    "                    tmp[i + 1][j] = 0\n",
    "                    tmp[i - 1][j] = 0\n",
    "                    tmp[i][j + 1] = 0\n",
    "                    tmp[i][j - 1] = 0\n",
    "                    #tmp[i + 1][j + 1] = 0\n",
    "                    #tmp[i + 1][j - 1] = 0\n",
    "                    #tmp[i - 1][j + 1] = 0\n",
    "                    #tmp[i - 1][j - 1] = 0\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "def swell(tmp):\n",
    "    copy = tmp.copy()\n",
    "    for i in range(len(tmp)):\n",
    "        for j in range(len(tmp[0])):\n",
    "            if copy[i][j] == 1:\n",
    "                if i > 0 and j > 0 and i < len(tmp) - 1 and j < len(tmp[0]) - 1:\n",
    "                    tmp[i + 1][j] = 1\n",
    "                    tmp[i - 1][j] = 1\n",
    "                    tmp[i][j + 1] = 1\n",
    "                    tmp[i][j - 1] = 1\n",
    "                    #tmp[i + 1][j + 1] = 1\n",
    "                    #tmp[i + 1][j - 1] = 1\n",
    "                    #tmp[i - 1][j + 1] = 1\n",
    "                    #tmp[i - 1][j - 1] = 1\n",
    "    \n",
    "    return tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "2328\n"
     ]
    }
   ],
   "source": [
    "size = [100, 100, 100, 100, 100, 79, 100, 100, 100, 77, 92, 100, 100, 100, 100, 100, 35, 100, 100, 100, 92, 84, 67, 80, 67, 55]\n",
    "\n",
    "print len(size)\n",
    "\n",
    "print sum(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showimage(tmp):\n",
    "    _=plt.matshow(tmp.reshape(newheight, newwidth),cmap=plt.cm.gray_r)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def getCoverage(tmp):\n",
    "    count = 0\n",
    "    for i in range(len(tmp)):\n",
    "        for j in range(len(tmp[0])):\n",
    "            if tmp[i][j] == 1:\n",
    "                count += 1\n",
    "    return float(count) / (len(tmp) * len(tmp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldata = []\n",
    "\n",
    "for samplenumber in range(11, 37):\n",
    "    for imgnumber in range(1, size[samplenumber - 11] + 1):\n",
    "        filepath = \"Img//Sample\" + '{0:03}'.format(samplenumber) + \" copy//img\" + '{0:03}'.format(samplenumber) + \"-\" + '{0:05}'.format(imgnumber) + \".png\"\n",
    "        im = Image.open(filepath)\n",
    "        imgsmall = im.resize((newwidth, newheight),Image.ANTIALIAS)\n",
    "        \n",
    "        tmp = []\n",
    "        \n",
    "        for h in range(0, imgsmall.size[1]): \n",
    "            #tmp = []\n",
    "            for w in range(0, imgsmall.size[0]): \n",
    "                pixel = imgsmall.getpixel((w, h))\n",
    "                g = 1 - float(pixel[0]) / 255 + 1 - float(pixel[1]) / 255 + 1 - float(pixel[2]) / 255\n",
    "                tmp.append(g / float(3))\n",
    "        \n",
    "        tmp = np.array(tmp).reshape(newheight, newwidth)\n",
    "        #showimage(tmp)\n",
    "        \n",
    "        tmp = process(tmp)\n",
    "\n",
    "        if (getCoverage(tmp) < 0.5):\n",
    "            tmp = swell(tmp)\n",
    "\n",
    "        if (getCoverage(tmp) > 0.4):\n",
    "            tmp = errosion(tmp)\n",
    "        \n",
    "        while(getCoverage(tmp) < 0.3):\n",
    "            tmp = swell(tmp)\n",
    "            \n",
    "        #showimage(tmp)\n",
    "        \n",
    "        alldata.append(np.array(tmp).flatten())\n",
    "        \n",
    "\n",
    "        #im = Image.fromarray(np.uint8((1 - tmp) * 255))\n",
    "        #im.save(\"Img//Sample\" + '{0:03}'.format(samplenumber) + \" copy//img\" + '{0:03}'.format(samplenumber) + \"-\" + '{0:05}'.format(imgnumber) +  \"copy2.png\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2328\n",
      "2328\n"
     ]
    }
   ],
   "source": [
    "alldata = np.array(alldata)\n",
    "\n",
    "label = []\n",
    "\n",
    "ch = 'A'\n",
    "for i in range(26):\n",
    "    for j in range(size[i]):\n",
    "        label.append([ch])\n",
    "    ch = chr(ord(ch) + 1)\n",
    "\n",
    "label = np.array(label).flatten()\n",
    "\n",
    "print len(alldata)\n",
    "print len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_comp_new = 40\n",
    "\n",
    "pca_new = PCA(n_comp_new)\n",
    "pca_new.fit(alldata)\n",
    "resizedata_pca = pca_new.transform(alldata)\n",
    "\n",
    "\n",
    "def cross(j):\n",
    "    accuracy = 0\n",
    "    for i in range(5):\n",
    "        x_train_resize, x_test_resize, y_train_resize, y_test_resize = train_test_split(resizedata_pca, label, test_size=0.30, random_state=1)\n",
    "\n",
    "        '''norm = Normalizer().fit(x_train_resize)           \n",
    "        x_train_resize = norm.transform(x_train_resize)          \n",
    "        x_test_resize = norm.transform(x_test_resize)'''\n",
    "\n",
    "        neigh = KNeighborsClassifier(n_neighbors = j)\n",
    "        neigh.fit(x_train_resize, y_train_resize)\n",
    "        #neigh_predict = neigh.predict(x_test)\n",
    "        accuracy += neigh.score(x_test_resize, y_test_resize)\n",
    "    \n",
    "    return accuracy / float(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAF5CAYAAABEPIrHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3X94ZVV97/H3t4BS9DK2jmGC0CqjIraKTJSWMlrtVCmt\nV8tMEaNcFdCWCqKDXMWqxYv1obUyKEUUvdKBWlOpTRWutljUqjM40CZl/IWCDCAtIYOKowIWZL73\nj70jZ0KSSc45yV45eb+e5zxnzjr7rHwXGXY+s9faK5GZSJIkleLnmi5AkiSpleFEkiQVxXAiSZKK\nYjiRJElFMZxIkqSiGE4kSVJRDCeSJKkohhNJklQUw4kkSSqK4USSJBWlmHASEadExM0RcW9EbImI\nZ+7m+JdFxHURcXdE3B4RH46IX2x5/ykR8fG6z50Rcdr8j0KSJHWqiHASEccB5wJnAYcBW4ErI2L5\nNMcfCVwCfAh4CvAHwOHAB1sO2we4CXgTMDZvxUuSpK6KEn7xX0RsAa7JzNfVrwO4DTg/M981xfFv\nAE7OzCe2tJ0KvDEzf2mK428GzsvM8+drDJIkqTsav3ISEXsBA8BnJ9qySkxXAUdM87EvAwdGxNF1\nH/sBxwKfmt9qJUnSfGs8nADLgT2A8Unt48CKqT6QmVcDxwMfi4j7qKZt7gJOncc6JUnSAtiz6QLa\nERFPAd4LvB34DNAPvBu4CHhVB/0+GjgKuAX4Sad1SpK0hOwNPA64MjO/10lHJYST7wIPAPtNat8P\nuGOaz5wJbM7MDfXrr0XEa4AvRcRbMnPyVZjZOgr42zY/K0mS4GXARzvpoPFwkpn3R8QIsAa4HH62\nIHYNMN0C1n2A+ya17QQSiA7KuQXgIx/5CIccckgH3ZRh/fr1nHfeeU2X0TWOp1y9NBZwPCXrpbFA\nb43n+uuv5/jjj4f6Z2knGg8ntQ3AxjqkXAuspwogGwEi4hxg/8x8RX38FcAHI+Jk4Epgf+A8qjt+\n7qg/sxfVbcYBPAx4bEQcCvw4M2+apo6fABxyyCGsWrWq64NcaMuWLeuJcUxwPOXqpbGA4ylZL40F\nem88tY6XRRQRTjLzsnpPk7OppnOuA47KzDvrQ1YAB7Ycf0lEPBI4hWqtyQ+o7vY5s6Xb/YH/oLqa\nAnBG/fgC8FvzNxpJktSJIsIJQGZeCFw4zXsnTNH2PuB9M/R3K2XcjSRJkubAH96SJKkohpMeNjg4\n2HQJXeV4ytVLYwHHU7JeGgv03ni6pYjt60sREauAkZGRkV5coCRJ0rwZHR1lYGAAYCAzRzvpyysn\nkiSpKIYTSW0bH4fVq2Hlyup5+/amK5LUCwwnktq2bh1s3gzbtlXPa9c2XZGkXmA4kdS2sbGZX0tS\nOwwnktrW3z/za0lqRzGbsElafIaHq6mcsbEqmAwPN12RpF5gOJHUtr4+2LSp6Sok9RqndSRJUlEM\nJ5IkqSiGE0mSVBTDiSRJKorhRJIkFcVwIkmSimI4kSRJRTGcSJKkohhOJElSUQwnkiSpKIYTSZJU\nFMOJJEkqiuFEkiQVxXAiSZKKYjiRJElFMZxIkqSiGE4kSVJRDCeSJKkohhNJklQUw4kkSSqK4USS\nJBXFcCJJkopiOJEkSUUxnEiSpKIYTqQFNj4Oq1fDypXV8/btTVckSWUxnEgLbN062LwZtm2rnteu\nbboiSSqL4URaYGNjM7+WpKXOcCItsP7+mV9L0lK3Z9MFSEvN8HA1lTM2VgWT4eGmK5KkshhOpAXW\n1webNjVdhSSVy2kdSZJUFMOJJEkqiuFEkiQVxXAiSZKKYjiRJElFMZxIkqSiGE4kSVJRDCeSJKko\nhhNJklQUw4kkSSqK4USSJBXFcCJJkopiOJEkSUUxnEiSpKIYTiRJUlEMJ5IkqSiGE0mSVBTDiSRJ\nKkox4SQiTomImyPi3ojYEhHP3M3xL4uI6yLi7oi4PSI+HBG/OOmYYyPi+rrPrRFx9PyOQpIkdaqI\ncBIRxwHnAmcBhwFbgSsjYvk0xx8JXAJ8CHgK8AfA4cAHW475DeCj9TFPBz4JfCIinjJ/I5EkSZ0q\nIpwA64GLMvPSzPwmcDJwD3DiNMf/OnBzZr4vM2/NzKuBi6gCyoTTgH/KzA2Z+a3M/FNgFDh1/oYh\nSZI61Xg4iYi9gAHgsxNtmZnAVcAR03zsy8CBE9M0EbEfcCzwqZZjjqj7aHXlDH1KkqQCNB5OgOXA\nHsD4pPZxYMVUH6ivlBwPfCwi7gPGgLvY9arIirn0KUmSyrBn0wW0o1438l7g7cBngH7g3VRTO6/q\ntP/169ezbNmyXdoGBwcZHBzstGtJkha9oaEhhoaGdmnbsWNH1/qPagalOfW0zj3Ausy8vKV9I7As\nM4+Z4jOXAntn5otb2o4EvgT0Z+Z4RNwKnJuZ57cc83bgRZl52DS1rAJGRkZGWLVqVVfGJ0nSUjA6\nOsrAwADAQGaOdtJX49M6mXk/MAKsmWiLiKhfXz3Nx/YBfjqpbSeQQNSvv9zaZ+15dbskSSpUKdM6\nG4CNETECXEt1984+wEaAiDgH2D8zX1EffwXwwYg4mWqR6/7AecA1mXlHfcx7gX+NiNOpFsoOUi28\nffWCjEiSJLWliHCSmZfVe5qcDewHXAcclZl31oesAA5sOf6SiHgkcArVWpMfUN3tc2bLMV+OiJcC\n76wfN1JN6XxjAYYkSZLaVEQ4AcjMC4ELp3nvhCna3ge8bzd9/gPwD10pUJIkLYjG15xIkiS1MpxI\nkqSiGE4kSVJRDCeSJKkohhOpB42Pw+rVsHJl9bx9e9MVSdLsGU6kHrRuHWzeDNu2Vc9r1zZdkSTN\nnuFE6kFjYzO/lqSSGU6kHtTfP/NrSSpZMZuwSeqe4eFqKmdsrAomw8NNVyRJs2c4kXpQXx9s2tR0\nFZLUHqd1JElSUQwnkiSpKIYTSZJUFMOJJEkqiuFkCiee6I6aUknc8VZaWgwnU9i61R01pZK44620\ntBhOpuGOmlI53PFWWloMJ9NwR02pHO54Ky0tbsI2hUMPdUdNqSTueCstLYaTKVx8cbXDpqQyuOOt\ntLQ4rSNJkopiOJEkSUUxnEiSpKIYTiRJUlEMJ5IkqSiGE0mSVBTDiSRJKorhRJIkFcVwIkmSimI4\nkSRJRTGcSJKkohhOJElSUQwnkiSpKIYTSZJUFMOJJEkqiuFEkiQVxXAiSZKKYjiRJElFMZxIkqSi\nGE4kSVJRDCeSJKkohhNJklQUw4kkSSqK4USSJBXFcCJJkopiOJEkSUUxnEiSpKIYTiRJUlEMJ5Ik\nqSiGE0mSVBTDiSRJKsqcw0lEHDQfhUiSJEF7V06+HRGfj4jjI2LvrlckSZKWtHbCySrgK8AG4I6I\nuCgiDu9uWZLUu8bHYfVqWLmyet6+vemKpLLMOZxk5nWZ+Tpgf+BEoB/YFBFfi4jTI+Ix3S5SknrJ\nunWweTNs21Y9r13bdEVSWdpeEJuZP83MYeBY4E3AE4B3A7dFxKUR0d+lGiWpp4yNzfxaWuraDicR\n8YyIuBAYA06nCiYrgedRXVX5ZFcqlKQe098/82tpqdtzrh+IiNOBE4CDgU8DLwc+nZk760NujohX\nArd0qUZJ6inDw9VUzthYFUyGh5uuSCpLO1dO/hj4KPDLmfn7mfn/WoLJhO3ASXPpNCJOiYibI+Le\niNgSEc+c4di/joidEfFA/Tzx+GrLMXtGxJ9GxLfrPv8jIo6aS02SNB/6+mDTJrjppuq5r6/piqSy\nzPnKSWY+cRbH3AdcMts+I+I44FzgD4FrgfXAlRHxpMz87hQfOY1qncuEPanuILqspe2dwEuBVwHf\nAn4H+MeIOCIzt862NkmStLDa2YTthIg4dor2YyPiFW3WsR64KDMvzcxvAicD91DdDfQQmfmjzNw+\n8QAOBx4FbGw57HjgnZl5ZWbekpkfoJqGekObNUqSpAXQzrTOm4HxKdq3A38y184iYi9gAPjsRFtm\nJnAVcMQsuzkRuCozb2tpezjw35OOuxdYPdcaJUnSwmknnPwS8J0p2m+t35ur5cAePDTwjAMrdvfh\n+pblo4EPTXrrSuD0iHhCVJ4HrKXal0WSJBVqzmtOqK6QPI2H3o1zKPC9TgtqwyuBu3jorcuvAz4I\nfBPYCdwEXMw0U0Wt1q9fz7Jly3ZpGxwcZHBwsAvlSpK0uA0NDTE0NLRL244dO7rWf1QzKHP4QMRf\nAMdR3U78xbr5N6l+8H88M8+YY397Ua0vWZeZl7e0bwSWZeYxu/n8DcDl033diHgY8OjMHIuIPwd+\nLzOfOs2xq4CRkZERVq1aNZdhSJK0pI2OjjIwMAAwkJmjnfTVzrTO24BrqNaI3Fs/PgN8jjbWnGTm\n/cAIsGaiLSKifn31TJ+NiOdQbfz24Rn6v68OJnsB64BPzLVGSZK0cNq5lfg+4LiIeBvVVM69wFcz\n89YO6tgAbIyIER68lXgf6rtvIuIcYP/MnHw30EnANZl5/eQO619G+FjgOuAA4CwggL/soE5JkjTP\n2llzAkBm3gDc0I0iMvOyiFgOnA3sRxUojsrMO+tDVgAHtn4mIvYFjqHa82QqewN/Bjwe+DHwKeD4\nzPxhN2qWJEnzo61wEhEHAC+kujvnYa3vZebp7fSZmRcCF07z3glTtP0QeOQM/X0R+JV2apEkSc1p\n53frrAEuB7YBTwa+BjyOasqkowUwkiRJ7SyIPQd4d33Hy0+oFpkeCHwB+Psu1iZJkpagdsLJIcCl\n9Z9/Cvx8Zv4Y+FN2/X03kiRJc9ZOOLmbB9eZjFHdyjtheccVSZKkJa2dcLKFB38/zaeBcyPiLVSb\nsG3pVmHShPFxWL0aVq6snrdvX9xfR5I0s3bu1jmdB++SOav+83HAjfV7UletWwebN1d/3rYN1q6F\nTZsW79eRJM1sTuEkIvag2tDsKwCZeTdw8jzUJf3M2NjMrxfb15EkzWxO0zqZ+QDVVvW/MD/lSA/V\n3z/z68X2dSRJM2tnWudrwEHAzV2uRZrS8HA1xTI2VgWG4eHF/XUkSTNrJ5y8FXh3/bt1Rqju3vkZ\nt4dXt/X1Lczaj4X6OpKkmbUTTj5dP18OZEt71K/36LQoSZK0dLUTTp7b9SokSZJqcw4nmfmF+ShE\nkiQJ2vvFf8+e6f36twFLkiS1pZ1pnX+doq117YlrTiQtSuPj1WZ8rXds9fU1XZW09LSzff0vTHr0\nAb8D/Bvw/O6VJkkLa2KX4G3bque1a5uuSFqa2llzsmOK5n+JiPuADcBAx1VJUgPcJVgqQztXTqYz\nDhzcxf4kaUG5S7BUhnYWxD5tchPQD5wJXNeNoiSpCe4SLJWhnQWx11EtgI1J7VuAEzuuSJIa4i7B\nUhnaCSePn/R6J3BnZv6kC/VIkqQlrp0FsbfORyGSJEnQxoLYiDg/Ik6dov3UiHhPd8qSJElLVTt3\n66wDppqVvRr4g87KkSRJS1074eTRwI+maP8hsLyzcrSYjI/D6tWwcmX1vH170xVJknpBO+Hk28DR\nU7QfDWzrrBwtJu6mKUmaD+3crbMBuCAiHgN8rm5bA7wBeH23ClP53E1TkjQf2rlb5+KIeDjwFuBt\ndfMtwB9n5qVdrE2F6++vrpq0vpYkqVPtXDkhM98PvL++enJvZv64u2VpMXA3TUnSfGhn+/rHA3tm\n5o2ZeWdL+xOB+zPzli7Wp4K5m6YkaT60syB2I/BrU7T/Wv2eJElS29oJJ4cBX56ifQvw9M7KkSRJ\nS1074SSBfadoXwbs0Vk5kiRpqWsnnHwReHNE/CyI1H9+M1PvHCtJkjRr7dyt8yaqgPKtiPhS3fYs\nqisnz+1WYZIkaWma85WTzPwG8DTgMqAP+B/ApcCTuluaJElaitrd5+R24E8AImJf4CXAPwPPwHUn\nkiSpA+2sOQEgIp4dEZcAtwNnAJ8Hfr1bhUmSpKVpTldOImIF8ErgJKo7di4DHg78fj3dI0mS1JFZ\nXzmJiCuAb1GtN3k9sH9mvna+CpMkSUvTXK6cHA2cD7w/M2+cp3okSdISN5c1J6up7swZiYhrIuLU\niFg+T3VJkqQlatbhJDO3ZOargX7gIqo7dG6v+3heRPyP+SlRkiQtJe3sc3J3Zl6cmauBpwLnAmcC\n2yPi8m4XKEmSlpa2byUGyMxvZeYbgQOAwe6UJEmSlrK2NmGbLDMfAD5RPyRJktrW0ZUTSZKkbjOc\nSJKkohhOJElSUQwnkiSpKIYTSZJUFMOJJEkqiuFEkiQVxXDSg8bHYfVqWLmyet6+vemKJDXBc4EW\nK8NJD1q3DjZvhm3bque1a5uuSFITPBdosTKc9KCxsZlfS1oaPBdosTKc9KD+/plfS1oaPBdoserK\n79ZRWYaHq8u3Y2PVyWh4uOmKJDXBc4EWq2LCSUScApwBrAC2Aq/NzH+b5ti/Bl4BJBAtb309M5/a\nctzrgZOBXwK+C3wceHNm/ve8DKIQfX2waVPTVUhqmucCLVZFTOtExHHAucBZwGFU4eTKiFg+zUdO\nowox/fXzAcD3gcta+nwpcE7d55OBE4EXA++cn1FIkqRuKCKcAOuBizLz0sz8JtXVjnuoAsVDZOaP\nMnP7xAM4HHgUsLHlsCOATZn5scz8TmZeBfxdfawkSSpU4+EkIvYCBoDPTrRlZgJXUQWM2TgRuCoz\nb2tpuxoYiIhn1l/nIOB3gU91o25JkjQ/SlhzshzYAxif1D4OHLy7D0dEP3A08JLW9swcqqeFNkVE\n1F/jA5n5F12pWpIkzYsSwkmnXgncBXyytTEingP8CdUU0bXAE4DzI2IsM/9spg7Xr1/PsmXLdmkb\nHBxkcHCwe1VLkrRIDQ0NMTQ0tEvbjh07utZ/VDMozamnde4B1mXm5S3tG4FlmXnMbj5/A3B5Zp4x\nqf2LwJbMfGNL28uo1rY8cpq+VgEjIyMjrFq1qt0hSZK05IyOjjIwMAAwkJmjnfTV+JqTzLwfGAHW\nTLTV0zBrqNaNTKu+OrIS+PAUb+8D/HRS286W/iVJUoFKmdbZAGyMiBGqKZj1VOFiI0BEnAPsn5mv\nmPS5k4BrMvP6Kfq8AlgfEVuBa4AnAmdTXWVp9nKRJEmaVhHhJDMvqxevng3sB1wHHJWZd9aHrAAO\nbP1MROwLHEO158lU3kF1peQdwGOBO4HLgbd2fQCSJKlriggnAJl5IXDhNO+dMEXbD4Ep147U708E\nk3d0q0ZJkjT/Gl9zIkmS1MpwIkmSimI4kSRJRTGcSJKkohhOJElSUQwnkiSpKIYTSZJUFMOJJEkq\niuFEkiQVxXAiSZKKYjiRJElFMZxIkqSiGE4kSVJRDCeSJKkohhNJklQUw4kkSSqK4USSJBXFcCJJ\nkopiOJEkSUUxnEiSpKIYTiRJUlEMJ5IkqSiGE0mSVBTDiSRJKorhRJIkFcVwIkmSimI4kSRJRTGc\nSJKkohhOJElSUQwnkiSpKIYTSZJUFMOJJEkqiuFEkiQVxXAiSZKKYjiRJElFMZxIkqSiGE4kSVJR\nDCeSJKkohhNJklQUw4kkSSqK4USSJBXFcCJJkopiOJEkSUUxnEiSpKIYTiRJUlEMJ5IkqSiGE0mS\nVBTDiSRJKorhRJIkFcVwIkmSimI4kSRJRTGcSJKkohhOJElSUQwnkiQtsPFxWL0aVq6snrdvb7qi\nshhOJElaYOvWwebNsG1b9bx2bdMVlcVwIknSAhsbm/n1Umc4kSRpgfX3z/x6qduz6QIkSVpqhoer\nqZyxsSqYDA83XVFZirlyEhGnRMTNEXFvRGyJiGfOcOxfR8TOiHigfp54fLXlmM9Pem/iccXCjEiS\npKn19cGmTXDTTdVzX1/TFZWliHASEccB5wJnAYcBW4ErI2L5NB85DVgB9NfPBwDfBy5rOeaY+r2J\nx68CD0w6RpIkFaaIcAKsBy7KzEsz85vAycA9wIlTHZyZP8rM7RMP4HDgUcDGlmN+MOmY5wN3Ax+f\n57FIkqQONB5OImIvYAD47ERbZiZwFXDELLs5EbgqM2/bzTFDmXlvu7VKkqT5V8KC2OXAHsD4pPZx\n4ODdfTgi+oGjgZfMcMzhwK8AJ7RfpiRJWgglhJNOvRK4C/jkDMecBHw1M0dm0+H69etZtmzZLm2D\ng4MMDg62W6Mk9aTx8WpDsda7Thbz4k7HMztDQ0MMDQ3t0rZjx47OO65FNYPSnHpa5x5gXWZe3tK+\nEViWmcfs5vM3AJdn5hnTvL8PcDvw1sy8YDd9rQJGRkZGWLVq1dwGIklL0OrV1Q6nE448srr7ZLFy\nPO0bHR1lYGAAYCAzRzvpq/E1J5l5PzACrJloi4ioX18902cj4jnASuDDMxz2YuBhwN92WqskaVe9\nttOp4ylD4+GktgF4dUS8PCKeDHwA2If67puIOCciLpnicycB12Tm9TP0fRLwicy8q8s1S9KS12s7\nnTqeMhSx5iQzL6v3NDkb2A+4DjgqM++sD1kBHNj6mYjYl2ovk9Om6zcingT8BvC8+ahbkpa6Xtvp\n1PGUofE1JyVxzYkkSe3pqTUnkiRJrQwnkiSpKIYTSZJUFMOJJEkqiuFkAY2PVxvirFxZPW/f3nRF\nkiSVx3CygNatq3bq27atel67tumKJEkqj+FkAS3WnfokSVpIhpMFtFh36pMkaSEVsUPsUrFYd+qT\nJGkhGU4WUF/f4v7tlpIkLQSndSRJUlEMJ5IkqSiGE0mSVBTDiSRJKorhRJJUPHfYLtv4OJx4Yvf6\nM5xIkornDttlW7cOtm7tXn+GE0lS8dxhu2zd/n4YTiRJxXOH7bJ1+/thOJEkFW94GI48Eg46qHp2\nh+2yDA/DoYd2rz93iJUkFc8dtsvW1wcXXwwDA93pzysnkiSpKIYTSZJUFMOJJEkqiuGkhw0NDTVd\nQlc5nnL10ljA8ZSsl8YCvTeebjGc9LBe+0vveMrVS2MBx1OyXhoL9N54usVwIkmSimI4kSRJRTGc\nSJKkorgJ2672Brj++uubrqMrduzYwejoaNNldI3jKVcvjQUcT8l6aSzQW+Np+dm5d6d9RWZ22kfP\niIiXAn/bdB2SJC1iL8vMj3bSgeGkRUQ8GjgKuAX4SbPVSJK0qOwNPA64MjO/10lHhhNJklQUF8RK\nkqSiGE4kSVJRDCeSJKkohhNJklQUw0ktIk6JiJsj4t6I2BIRz2y6pnZExJsj4tqI+GFEjEfEP0bE\nk5quqxsi4syI2BkRG5qupV0RsX9E/E1EfDci7omIrRGxqum62hERPxcR74iIbfVYvh0Rb226rtmK\niGdFxOUR8V/136sXTnHM2RFxez2+f4mIJzRR6+7MNJaI2DMi/iIivhIRP66PuSQi+puseSaz+d60\nHPuB+pjTFrLGuZjl37VDIuKTEfGD+vt0TUQc0ES9M9ndWCLiERFxQUTcVv9/8/WI+KO5fh3DCRAR\nxwHnAmcBhwFbgSsjYnmjhbXnWcBfAb8G/DawF/CZiPj5RqvqUB0W/5Dqe7MoRcSjgM3Af1Pdsn4I\n8Abgribr6sCZwB8BrwGeDLwReGNEnNpoVbP3COA6qvofcttiRLwJOJXq793hwN1U54WHLWSRszTT\nWPYBng78H6rz2zHAwcAnF7LAOZrxezMhIo6hOtf91wLV1a7d/V1bCXwJ+AbwbOCpwDsoc0uL3X1v\nzgOeD7yU6rxwHnBBRLxgTl8lM5f8A9gCvLfldQD/Cbyx6dq6MLblwE5gddO1dDCGRwLfAn4L+Dyw\noema2hzHnwNfaLqOLo7nCuBDk9o+DlzadG1tjGUn8MJJbbcD61te7wvcC7y46XrnOpYpjnkG8ABw\nQNP1tjse4LHAd6hC/s3AaU3X2u54gCHgkqZr69JYvgq8ZVLbvwNnz6XvJX/lJCL2AgaAz060ZfVf\n8yrgiKbq6qJHUaXb7zddSAfeB1yRmZ9rupAO/U/g3yPisnrKbTQiXtV0UR24GlgTEU8EiIhDgSOB\nTzdaVRdExOOBFex6XvghcA29dV74QdOFtCMiArgUeFdmLurfN1KP5feAGyPin+tzw5aIeFHTtbXp\nauCFEbE/QEQ8F3gicOVcOlny4YTqysIewPik9nGqk9OiVf+lfw+wKTO/0XQ97YiIl1Bdkn5z07V0\nwUHAH1NdBXo+8H7g/Ij4X41W1b4/Bz4GfDMi7gNGgPdk5t81W1ZXrKD64d2L54WHU33vPpqZP266\nnjadCdyXmRc0XUgX9FFdHX4TVbB/HvCPwHBEPKvJwtr0WuB64D/r88KngVMyc/NcOvEX//W2C4Gn\nUP1rdtGpF4O9B/jtzLy/6Xq64OeAazPzbfXrrRHxq8DJwN80V1bbjqOaV34J1Vz504H3RsTtmbkY\nx9PzImJP4O+pgtdrGi6nLRExAJxGtX6mF0xcJPhEZp5f//krEfEbVOeGLzVTVttOo1oH9AKqabdn\nAxfW54VZX/02nMB3qeZe95vUvh9wx8KX0x0RcQHwu8CzMnOs6XraNAA8BhitrwJBdZXr2fWiy4fX\nU3CLxRjVvyhaXQ+sbaCWbngXcE5m/n39+usR8Tiqq1yLPZzcQbX2bD92vXqyH/AfjVTUoZZgciDw\nW4v4qslqqvPCbQ+eFtgD2BARr8/MgxqrrD3fBX7K1OeGRfUPy4jYG3gn8PuZ+U9189ci4jDgDGDW\n4WTJT+vU/yIfAdZMtNU/CNdQzZ0tOnUweRHw3Mz8TtP1dOAqqlXrTwcOrR//DnwEOHSRBROo7tQ5\neFLbwcCtDdTSDftQBftWO+mB80pm3kwVUFrPC/tS/Ytw0Z0XWoLJQcCazFysd4hBtdbkaTx4TjiU\navHyu6jugltU6p9B/8ZDzw1PYvGdG/aqH5PPCw8wx/OCV04qG4CNETECXAuspzrxbmyyqHZExIXA\nIPBC4O6ImLgitCMzS7wtbVqZeTfVdMHPRMTdwPcW6SK484DNEfFm4DKqH3SvAl7daFXtuwJ4a0T8\nJ/B1YBXV/zv/t9GqZikiHgE8geoKCcBB9aLe72fmbVRTim+NiG9T/abyd1DdxVfcLbgzjYXqit0/\nUIX8FwB7tZwXvl/ilOksvjd3TTr+fuCOzLxxYSudnVmM5y+Bv4uIL1HdkXg01ffqN5uodya7G0tE\nfAF4d0QUp7rDAAAB7ElEQVS8lipcPQd4OfD6OX2hpm9FKuVBNf96C9Wtgl8GntF0TW2OYydVSp38\neHnTtXVpfJ9jkd5KXNf/u8BXgHuofqCf2HRNHYzlEVTB/maqPUBupNpLY8+ma5tl/b85zf8vF7cc\n83aqf5XfQ3W3wROarnuuYwF+eYr3Jl4/u+na2/3eTDp+GwXfSjzLv2uvBG6o/18aBV7QdN3tjIVq\nge+HgdvqsXwDeN1cv07UnUmSJBVh0c8NS5Kk3mI4kSRJRTGcSJKkohhOJElSUQwnkiSpKIYTSZJU\nFMOJJEkqiuFEkiQVxXAiSZKKYjiRVLSI+HxEbGi6DkkLx3AiSZKKYjiRJElFMZxIWlQi4vci4gcR\nMdh0LZLmx55NFyBJsxURLwUuBAYz85+arkfS/PDKiaRFISJeA1wAvMBgIvU2r5xIWgyOBR4DHJmZ\nI00XI2l+eeVE0mIwCtwJnNR0IZLmn+FE0mJwE/Bc4EUR8VdNFyNpfjmtI2lRyMxvR8Rzgc9HxE8z\nc33TNUmaH4YTSaXLn/0h84aIWMODAeV/N1iXpHkSmbn7oyRJkhaIa04kSVJRDCeSJKkohhNJklQU\nw4kkSSqK4USSJBXFcCJJkopiOJEkSUUxnEiSpKIYTiRJUlEMJ5IkqSiGE0mSVJT/DxqUdla1twBz\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12810ae90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79685264663805433, 0.76824034334763946, 0.7811158798283262, 0.78540772532188841, 0.78826895565092991, 0.78826895565092991, 0.80400572246065816, 0.79828326180257514, 0.80829756795422036, 0.79685264663805433, 0.7868383404864091, 0.79113018597997142, 0.7811158798283262, 0.76967095851216027, 0.76680972818311877, 0.76967095851216027, 0.77110157367668097, 0.76967095851216027, 0.76680972818311877]\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "\n",
    "for i in range(1, 20):\n",
    "    acc.append(cross(i))\n",
    "\n",
    "plt.plot(acc,'.')\n",
    "plt.xlabel('k')\n",
    "_=plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "print acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.576537911302\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(alldata, label, test_size=0.30, random_state=1)\n",
    "  \n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(x_train, y_train)\n",
    "\n",
    "tree_predicted = clf.predict(x_test)\n",
    "print clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2328\n",
      "0.809728183119\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "numlabel = []\n",
    "\n",
    "for i in range(len(label)):\n",
    "    numlabel.append(ord(label[i]) - ord('A'))\n",
    "    \n",
    "print len(numlabel)\n",
    "\n",
    "# svm\n",
    "x_train, x_test, y_train, y_test = train_test_split(alldata, numlabel, test_size=0.30, random_state=1)\n",
    "\n",
    "clf = svm.SVC(kernel = 'linear', decision_function_shape = 'ovr')\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred_test = clf.predict(x_test)\n",
    "\n",
    "print clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if alldata 0.80\n",
    "### resizedata_pca 0.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
